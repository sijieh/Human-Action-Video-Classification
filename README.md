# ğŸ¥ Human-Action-Video-Classification

This project implements a two-stage deep learning pipeline that combines human action recognition with video style transfer.

---

## ğŸ§  Stage 1: Video Classification with ResNet

Classify human actions in videos using transfer learning with ResNet.

### ğŸ”¹ Dataset
- **UCF101**: A benchmark dataset of 13,000+ video clips across 101 human action categories (e.g., basketball dunk, archery, jumping jack).

### ğŸ”¹ Preprocessing
- Extracted and resized frames from video clips.
- Prepared frame sequences suitable for CNN input.

### ğŸ”¹ Model
- Utilized pre-trained **ResNet50** as the feature extractor.
- Appended a custom classification head for multi-class prediction.

### ğŸ”¹ Training
- Fine-tuned on a subset of UCF101 using standard data augmentation and learning rate scheduling.

---

## ğŸ“Š Model Evaluation

- **Validation Accuracy**: ~96%

---

## ğŸ¨ Stage 2: Style Transfer with CycleGAN

Stylize video frames while preserving their semantic content (pose/action).

### ğŸ”¹ Objective
- Transfer video appearance to another visual domain (e.g., natural to artistic) **without requiring paired data**.

### ğŸ”¹ Architecture
- Implemented **CycleGAN** with ResNet-based generators and cycle-consistency loss.

### ğŸ”¹ Result
- Maintains motion and pose accuracy while transforming frame appearance into a target artistic style.

---

## âœ¨ Features

- âœ… Frame-by-frame transformation using pre-trained **CycleGAN** weights.
- âœ… Option to run **real-time video stylization** via `streamlit_cyclegan_video.py`.
- âœ… Supports applying models to individual frames or full video sequences.

---

## ğŸ“ Project Structure

- `video_classification/` â€” ResNet training, evaluation, and preprocessing
- `style_transfer/` â€” CycleGAN scripts for training and stylization
- `notebooks/` â€” Visualizations and experiments
- `streamlit_cyclegan_video.py` â€” Real-time stylization web app
- `data/` â€” Sample input frames and class labels
